{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139a4762",
   "metadata": {},
   "source": [
    "# AI VISION WORKSHOP\n",
    "Our first step, as in most Python programs, is to import the external Python code modules that we will be using.  Note this first step assumes that your Python virtual environment is activated and all of these packages/modules have already been installed in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7606742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import webcolors\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import serial\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da03f25",
   "metadata": {},
   "source": [
    "Next we need to set the credentials that we'll use to connect to the Azure AI services and get responses to our API calls.  Note that these credentials are unique to each individual user.  It is best practice to store these in a separate local file and then import them into your code.  The local file is marked so as not to be uploaded or shared in any version control systems such as GitHub.\n",
    "\n",
    "Be sure to log in to your Azure account (portal.azure.com), create a 'Computer Vision' resource and a storage blob (details in workshop lab instructions), and note the unique endpoint, security key, and storage blob connection string.  Those values should be saved into a local file named config.py which we'll import below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea468d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the credentials that we will use to connect to the various Azure services (stored in a separate local file outside of git)\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181dca28",
   "metadata": {},
   "source": [
    "Now we'll set some static global variables that will be used later in the program... Note that you might need to change the COM port based on what is used on your system.  You can determine what port to use by opening the Windows Device Manager after plugging in your Arduino board and check under 'Ports (COM & LPT)' to see which port has been configured as the USB-SERIAL connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5f46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static global variables are defined here...\n",
    "img_file = '.\\\\WEBCAM-IMAGES\\\\sort-object.jpg'  # The name (and file path) of the image file which will be captured and analyzed\n",
    "com_port = 'COM6'  # COM port for Arduino board connection (USB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7cacc",
   "metadata": {},
   "source": [
    "Next we'll create the basic functions of our code that depend on your local computer:\n",
    "\n",
    "1. Capturing an image from your webcam\n",
    "2. Opening an image for display on the screen\n",
    "3. Uploading an image into a storage blob container in Azure\n",
    "4. Move the servo motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e013ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_frame_from_webcam():\n",
    "    \"\"\"Returns a single frame (image) from the webcam\"\"\"\n",
    "    print(\"Press c to capture the frame...\")\n",
    "\n",
    "    #Loop to continuously get frames from the webcam until user types a 'c'\n",
    "    while(True):\n",
    "        #Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #If frame was read correctly, show it\n",
    "        if ret:\n",
    "            cv2.imshow(\"Webcam Feed\", frame)\n",
    "\n",
    "     #Break the loop when 'c' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            break\n",
    "\n",
    "    # Capture a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Save the captured image\n",
    "    if ret:\n",
    "        cv2.imwrite(img_file, frame) # This overwrites the existing jpeg file defined in the static global variable defined above\n",
    "        print(\"\\nWebcam image captured...\\n\")\n",
    "    else:\n",
    "        print(\"\\nError capturing image\\n\")\n",
    "\n",
    "    #Release the capture object and destroy all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def open_image_in_new_window(image_path):\n",
    "    \"\"\"Opens an image file in a new window using Pillow.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img.show()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at '{image_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(img_file, container_name, blob_name):\n",
    "    \"\"\"Uploads a file to an Azure blob storage container.\"\"\"\n",
    "    # Create a BlobServiceClient\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(config.storage_connection_string)\n",
    "\n",
    "    # Get a client to interact with the specified container\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "    # Create the container if it does not exist\n",
    "    try:\n",
    "        container_client.create_container()\n",
    "    except Exception as e:\n",
    "        #print(f\"Error detail: {e}\")  # Uncomment this if more detail on the error message is needed\n",
    "        print(\"Azure blob container already exists or could not be created\")\n",
    "\n",
    "    # Upload the file\n",
    "    with open(img_file, \"rb\") as data:\n",
    "        container_client.upload_blob(name=blob_name, data=data, overwrite=True)\n",
    "\n",
    "    # Construct and return the URL of the uploaded file\n",
    "    blob_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}\"\n",
    "    return blob_url\n",
    "\n",
    "\n",
    "\n",
    "def move_servo(angle):\n",
    "    \"\"\"Moves the servo motor connected to the Arduino to the specified angle.\"\"\"\n",
    "    try:\n",
    "        arduino = serial.Serial(com_port, 9600, timeout=1)\n",
    "        time.sleep(2)   # Give time for the serial port to initialize\n",
    "        arduino.write(bytes([angle]))\n",
    "        time.sleep(1)  # Give time for the servo to move\n",
    "\n",
    "        arduino.close()  # Close the serial port connection\n",
    "        \n",
    "    except serial.SerialException as e:\n",
    "        print(f\"Error communicating with Arduino: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401bcf7c",
   "metadata": {},
   "source": [
    "Now we'll use these functions to open up the webcam and capture an image.  Note that the camera index might change based on your system.  Also, the 'img_file' variable value defined above has to already exist - if you get errors when trying to write the image it's likely a path issue (check what your current working directory is when running this notebook/cell) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b98690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press c to capture the frame...\n",
      "\n",
      "Webcam image captured...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)  # Note we need to use the correct index of the usb attached camera \n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam - make sure it is attached\")\n",
    "\n",
    "# Create a window named \"Webcam Feed\" to display what the webcam is seeing on to the console\n",
    "cv2.namedWindow(\"Webcam Feed\")\n",
    "\n",
    "# Call the capture frame function here\n",
    "get_image_frame_from_webcam()\n",
    "\n",
    "# Call the function to open the webcam image in a new window and show it on the console\n",
    "open_image_in_new_window(img_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394bc823",
   "metadata": {},
   "source": [
    "Now we'll upload the image file into an Azure storage blob so that we can use it as input (via it's public url) into various Azure Vision API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a698731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure blob container already exists or could not be created\n",
      "\n",
      "Uploaded file URL in Azure is:  https://aistoragewkshp.blob.core.windows.net/ai-vision-test/sort-object\n"
     ]
    }
   ],
   "source": [
    "# Now write the image into the azure blob storage container so that we can run various Azure AI tools against it...\n",
    "container_name = \"ai-vision-test\"  # This is the storage container created in the Azure environment\n",
    "blob_name = \"sort-object\"  # The name to assign to the uploaded file\n",
    "\n",
    "# Upload the file and print the URL to the screen\n",
    "uploaded_file_url = upload_blob(img_file, container_name, blob_name)\n",
    "print(\"\\nUploaded file URL in Azure is: \", uploaded_file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d4c32",
   "metadata": {},
   "source": [
    "Now we use the Azure AI Vision APIs to analyze the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88310696",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (358340941.py, line 41)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mif result.people is not None:\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Analyze the image...\n",
    "\n",
    "# Create an Image Analysis client to talk to the Azure Vision API service\n",
    "ia_client = ImageAnalysisClient(\n",
    "    endpoint=config.az_endpoint,\n",
    "    credential=AzureKeyCredential(config.key)\n",
    ")\n",
    "\n",
    "# Analyze the image.\n",
    "result = ia_client.analyze_from_url(\n",
    "    image_url=uploaded_file_url,\n",
    "    visual_features=[VisualFeatures.CAPTION, VisualFeatures.READ,VisualFeatures.TAGS,VisualFeatures.OBJECTS,VisualFeatures.PEOPLE],\n",
    "    gender_neutral_caption=True,  # Optional (default is False)\n",
    ")\n",
    "\n",
    "# Print generated caption results to the console\n",
    "print(\"\\nImage Analysis result returned this caption: \")\n",
    "if result.caption is not None:\n",
    "    print(f\"   '{result.caption.text.capitalize()}'\")\n",
    "\n",
    "# Print text (OCR) analysis results to the console\n",
    "print(\"\\nText found in the image (if any): \")\n",
    "if result.read.blocks:\n",
    "    for line in result.read.blocks[0].lines:\n",
    "        print(f\"   '{line.text}'\")\n",
    "\n",
    "# Print TAG analysis results to the console\n",
    "print(\"\\nTags for this image (if any): \")\n",
    "if result.tags:\n",
    "    for tag in result.tags.list:\n",
    "            print(f\"   '{tag.name}', Confidence {tag.confidence:.4f}\")\n",
    "\n",
    "# Print OBJECT analysis results to the console\n",
    "print(\"\\nObjects found in this image (if any): \")\n",
    "if result.objects is not None:\n",
    "    for object in result.objects.list:\n",
    "        print(f\"   '{object.tags[0].name}', {object.bounding_box}, Confidence: {object.tags[0].confidence:.4f}\")\n",
    "\n",
    "# Print PEOPLE analysis results to the console\n",
    "print(\"\\nPeople found in this image (if any): \")\n",
    "if result.people is not None:\n",
    "    for person in result.people.list:\n",
    "        print(f\"   {person.bounding_box}, Confidence {person.confidence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603d679",
   "metadata": {},
   "source": [
    "Code for moving the servo - note that you can edit the angle value to test this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a702da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 90 # This is an example angle to move the servo to 0 play around with changing it and rerunning this code block\n",
    "move_servo(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffa8f1",
   "metadata": {},
   "source": [
    "Finally - tie the two together and move the servo based on some output from the Azure Vision API calls.\n",
    "Here is an example where the servo rotates right/left based on whether the image contains a phone or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6ffd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There is a phone in the image so rotate the servo to 180 degrees...\n"
     ]
    }
   ],
   "source": [
    "if \"phone\" in result.caption.text:\n",
    "    print(\"\\nThere is a phone in the image so rotate the servo to 180 degrees...\")\n",
    "    move_servo(180)\n",
    "else:\n",
    "    print(\"\\nNo phone detected in the image so rotate the servo to 0 degrees...\")\n",
    "    move_servo(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
